{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d83b7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ======================\n",
    "# 0) è®€å–è³‡æ–™\n",
    "# ======================\n",
    "train = pd.read_excel(\"train.xlsx\")\n",
    "test  = pd.read_excel(\"test.xlsx\")\n",
    "\n",
    "# æ¨™ç±¤æ¬„\n",
    "TARGET_COL = \"å´©å¡Œ\"\n",
    "if TARGET_COL not in train.columns:\n",
    "    raise ValueError(f\"æ‰¾ä¸åˆ°æ¨™ç±¤æ¬„ï¼š{TARGET_COL}\")\n",
    "\n",
    "# ç‰¹å¾µ / æ¨™ç±¤ï¼ˆå…ˆç”¨å…¨éƒ¨æ•¸å€¼ç‰¹å¾µï¼Œè‹¥å«éæ•¸å€¼è«‹å…ˆè½‰å‹æˆ–å‰”é™¤ï¼‰\n",
    "X_full_all = train.drop(columns=[TARGET_COL])\n",
    "y          = train[TARGET_COL]\n",
    "\n",
    "# ======================\n",
    "# 1) åˆ‡åˆ†èˆ‡è£œå€¼ï¼ˆä»¥è¨“ç·´é›†çµ±è¨ˆé‡ fitï¼Œå†å¥—åˆ° val/testï¼‰\n",
    "# ======================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_full_all, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imp = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_val_imp   = pd.DataFrame(imputer.transform(X_val),     columns=X_val.columns,   index=X_val.index)\n",
    "X_test_imp  = pd.DataFrame(imputer.transform(test[X_full_all.columns]), columns=X_full_all.columns, index=test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dfee6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 30 Feature Importances (RandomForest on imputed data) ===\n",
      "   feature  importance\n",
      "0     æ¤ç”ŸæŒ‡æ¨™    0.064404\n",
      "1      æ–·å±¤è·    0.040189\n",
      "2     f_85    0.039264\n",
      "3     æœ€å°æ›²ç‡    0.017262\n",
      "4     f_32    0.013955\n",
      "5     f_48    0.013595\n",
      "6     å¹³å‡å¡å‘    0.012269\n",
      "7    f_199    0.011646\n",
      "8    f_141    0.006675\n",
      "9    é †å‘å¡æŒ‡æ¨™    0.006155\n",
      "10   f_108    0.005829\n",
      "11   f_175    0.005557\n",
      "12     f_5    0.005438\n",
      "13    f_70    0.005412\n",
      "14   f_164    0.005336\n",
      "15   f_119    0.005301\n",
      "16    f_64    0.005217\n",
      "17   f_185    0.005188\n",
      "18   f_126    0.005155\n",
      "19   f_186    0.005120\n",
      "20   f_142    0.005114\n",
      "21    f_27    0.005086\n",
      "22   f_151    0.005054\n",
      "23   f_128    0.005047\n",
      "24   f_153    0.005040\n",
      "25   f_173    0.005026\n",
      "26    f_80    0.005010\n",
      "27     f_7    0.005009\n",
      "28   f_109    0.004994\n",
      "29   f_200    0.004980\n",
      "\n",
      ">>> ä½¿ç”¨å‰ 10 å€‹ç‰¹å¾µï¼š['æ¤ç”ŸæŒ‡æ¨™', 'æ–·å±¤è·', 'f_85', 'æœ€å°æ›²ç‡', 'f_32', 'f_48', 'å¹³å‡å¡å‘', 'f_199', 'f_141', 'é †å‘å¡æŒ‡æ¨™']\n"
     ]
    }
   ],
   "source": [
    "# 2) è£œå€¼å¾Œå†è¨“ç·´éš¨æ©Ÿæ£®æ— â†’ æ‰¾å‰ 30 åé‡è¦ç‰¹å¾µ\n",
    "# ======================\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=50, n_estimators=200, n_jobs=-1)\n",
    "rf.fit(X_train_imp, y_train)\n",
    "\n",
    "importances   = rf.feature_importances_\n",
    "feature_names = X_train_imp.columns\n",
    "\n",
    "feat_imp = (\n",
    "    pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "      .sort_values(by='importance', ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\n=== Top 30 Feature Importances (RandomForest on imputed data) ===\")\n",
    "print(feat_imp.head(30))\n",
    "\n",
    "# 3) å–å‰ 10 åè¦†å¯« selected_featuresï¼Œä¸¦æŠŠ train/val/test éƒ½åˆ‡åˆ°é€™ 10 æ¬„\n",
    "# ======================\n",
    "top_n = 10\n",
    "selected_features = feat_imp.head(top_n)['feature'].tolist()\n",
    "print(f\"\\n>>> ä½¿ç”¨å‰ {top_n} å€‹ç‰¹å¾µï¼š{selected_features}\")\n",
    "\n",
    "# ä»¥ã€Œå‰åç‰¹å¾µã€é‡å»ºè³‡æ–™çŸ©é™£ï¼ˆå·²è£œå€¼ç‰ˆæœ¬ï¼‰\n",
    "X_train_sel = X_train_imp[selected_features].copy()\n",
    "X_val_sel   = X_val_imp[selected_features].copy()\n",
    "\n",
    "# test ä¹Ÿä»¥ç›¸åŒç‰¹å¾µåˆ‡å‡ºï¼›è‹¥ test å°‘æ¬„ä½å°±å ±éŒ¯æç¤º\n",
    "missing_in_test = [c for c in selected_features if c not in X_test_imp.columns]\n",
    "if missing_in_test:\n",
    "    raise ValueError(f\"test ç¼ºå°‘ä»¥ä¸‹å‰åç‰¹å¾µï¼š{missing_in_test}ï¼Œè«‹ç¢ºèª test æ¬„ä½æˆ–ç‰¹å¾µå·¥ç¨‹æµç¨‹ä¸€è‡´ã€‚\")\n",
    "X_test_sel  = X_test_imp[selected_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23d068ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation ROC-AUC = 0.8566 | PR-AUC = 0.5585\n",
      "æœ€ä½³ F1=0.5591 å°æ‡‰ threshold=0.3700\n",
      "\n",
      "=== Validation Report @ Best-F1 Threshold (CPU) ===\n",
      "Accuracy : 0.8030\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9533    0.8150    0.8787      1276\n",
      "           1     0.3552    0.7182    0.4753       181\n",
      "\n",
      "    accuracy                         0.8030      1457\n",
      "   macro avg     0.6542    0.7666    0.6770      1457\n",
      "weighted avg     0.8790    0.8030    0.8286      1457\n",
      "\n",
      "Confusion matrix:\n",
      " [[1040  236]\n",
      " [  51  130]]\n"
     ]
    }
   ],
   "source": [
    "# 2) XGBoostï¼šå–®æ¨¡è¨“ç·´ï¼ˆCPU-onlyï¼Œä½¿ç”¨ã€Œå‰åç‰¹å¾µ + å·²è£œå€¼ã€çš„ X_train_sel / X_val_selï¼‰\n",
    "# ======================\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, accuracy_score,\n",
    "    classification_report, confusion_matrix, f1_score, roc_curve\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# é¡åˆ¥ä¸å¹³è¡¡æ¬Šé‡ï¼ˆneg/posï¼‰â€” ä»¥ç›®å‰è¨“ç·´å­é›† y_train ç‚ºæº–\n",
    "pos_cnt = (y_train == 1).sum()\n",
    "neg_cnt = (y_train == 0).sum()\n",
    "scale_pos_weight = (neg_cnt / max(pos_cnt, 1))\n",
    "\n",
    "def make_xgb_params(spw=None):\n",
    "    return dict(\n",
    "        n_estimators=10000,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        min_child_weight=1,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        scale_pos_weight=scale_pos_weight if spw is None else spw,\n",
    "        tree_method=\"hist\",   # CPU\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "# å–®æ¨¡è¨“ç·´ç”¨ã€Œå·²è£œå€¼ + å‰åç‰¹å¾µã€\n",
    "xgb_clf = xgb.XGBClassifier(**make_xgb_params())\n",
    "xgb_clf.fit(X_train_sel, y_train)\n",
    "\n",
    "# é©—è­‰é›†è©•ä¼°ï¼ˆåŒæ¨£ç”¨ã€Œå·²è£œå€¼ + å‰åç‰¹å¾µã€ï¼‰\n",
    "y_val_proba = xgb_clf.predict_proba(X_val_sel)[:, 1]\n",
    "roc = roc_auc_score(y_val, y_val_proba)\n",
    "pra = average_precision_score(y_val, y_val_proba)\n",
    "print(f\"\\nValidation ROC-AUC = {roc:.4f} | PR-AUC = {pra:.4f}\")\n",
    "\n",
    "# æ‰¾æœ€ä½³ F1 é–€æª»\n",
    "best_thr, best_f1 = 0.5, 0.0\n",
    "for t in np.linspace(0.0, 1.0, 201):\n",
    "    y_pred = (y_val_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "    if f1 > best_f1:\n",
    "        best_thr, best_f1 = t, f1\n",
    "print(f\"æœ€ä½³ F1={best_f1:.4f} å°æ‡‰ threshold={best_thr:.4f}\")\n",
    "\n",
    "best_thr = 0.005\n",
    "y_val_pred = (y_val_proba >= best_thr).astype(int)\n",
    "print(\"\\n=== Validation Report @ Best-F1 Threshold (CPU) ===\")\n",
    "print(f\"Accuracy : {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "print(classification_report(y_val, y_val_pred, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84f4b07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] ROC-AUC=0.8904 | PR-AUC=0.6586\n",
      "[Fold 2] ROC-AUC=0.8436 | PR-AUC=0.5927\n",
      "[Fold 3] ROC-AUC=0.8703 | PR-AUC=0.6141\n",
      "[Fold 4] ROC-AUC=0.8946 | PR-AUC=0.6335\n",
      "[Fold 5] ROC-AUC=0.8635 | PR-AUC=0.5622\n"
     ]
    }
   ],
   "source": [
    "# 3) 5-fold é›†æˆï¼ˆæ¯æŠ˜å„è‡ªè£œå€¼ï¼‹å‰åç‰¹å¾µï¼ŒCPU-onlyï¼Œé¿å…è³‡æ–™æ´©æ¼ï¼‰\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# æé†’ï¼šX_full_sel æ˜¯ä½ åœ¨ã€ŒRF ç¯©åç‰¹å¾µã€å¾Œï¼Œå°šæœªè£œå€¼çš„å®Œæ•´ç‰¹å¾µè¡¨ï¼ˆtrain çš„é‚£ä»½ï¼‰\n",
    "X_full_sel = train[selected_features].copy()\n",
    "\n",
    "test_proba_blend = np.zeros(len(X_test_sel))  # å·²è£œå€¼å¾Œä¹‹ testï¼ˆå‰åç‰¹å¾µï¼‰çš„é•·åº¦\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_id = 1\n",
    "for tr_idx, va_idx in skf.split(X_full_sel, y):\n",
    "    # åˆ†å‰²ç•¶æŠ˜è³‡æ–™ï¼ˆæœªè£œå€¼ã€ä½†åªå«å‰åç‰¹å¾µï¼‰\n",
    "    X_tr_raw, X_va_raw = X_full_sel.iloc[tr_idx], X_full_sel.iloc[va_idx]\n",
    "    y_tr,     y_va     = y.iloc[tr_idx],        y.iloc[va_idx]\n",
    "\n",
    "    # æ¯æŠ˜ä»¥ã€Œç•¶æŠ˜è¨“ç·´å­é›†ã€çš„çµ±è¨ˆé‡åšè£œå€¼ï¼ˆmedianï¼‰\n",
    "    imp_k = SimpleImputer(strategy='median')\n",
    "    X_tr  = pd.DataFrame(imp_k.fit_transform(X_tr_raw), columns=X_tr_raw.columns, index=X_tr_raw.index)\n",
    "    X_va  = pd.DataFrame(imp_k.transform(X_va_raw),     columns=X_va_raw.columns, index=X_va_raw.index)\n",
    "    X_te  = pd.DataFrame(imp_k.transform(X_test_sel),   columns=X_test_sel.columns, index=X_test_sel.index)\n",
    "\n",
    "    # æ¯æŠ˜èª¿æ•´é¡åˆ¥æ¬Šé‡ï¼ˆneg/posï¼‰\n",
    "    spw = (y_tr == 0).sum() / max((y_tr == 1).sum(), 1)\n",
    "\n",
    "    # ç´” CPU è¨“ç·´\n",
    "    mdl = xgb.XGBClassifier(**make_xgb_params(spw))\n",
    "    mdl.fit(X_tr, y_tr)\n",
    "\n",
    "    # æŠ˜å…§é©—è­‰è§€å¯Ÿï¼ˆå¯ç•¥ï¼‰\n",
    "    oof = mdl.predict_proba(X_va)[:, 1]\n",
    "    fold_roc = roc_auc_score(y_va, oof)\n",
    "    fold_pr  = average_precision_score(y_va, oof)\n",
    "    print(f\"[Fold {fold_id}] ROC-AUC={fold_roc:.4f} | PR-AUC={fold_pr:.4f}\")\n",
    "    fold_id += 1\n",
    "\n",
    "    # å° test ç´¯åŠ å¹³å‡æ©Ÿç‡ï¼ˆä»¥æ¯æŠ˜çš„ imputer è½‰æ›éçš„ X_teï¼‰\n",
    "    test_proba_blend += mdl.predict_proba(X_te)[:, 1] / skf.n_splits\n",
    "#     # --- åˆå§‹åŒ– ---\n",
    "# test_proba_blend = np.zeros(len(X_te))\n",
    "# fold_pr_scores = []  # å„²å­˜æ¯æŠ˜çš„ PR-AUCï¼Œç¨å¾ŒåšåŠ æ¬Šå¹³å‡\n",
    "\n",
    "# for fold_id, (tr_idx, va_idx) in enumerate(skf.split(X_tr, y_tr), 1):\n",
    "#     X_tr_f, X_va_f = X_tr.iloc[tr_idx], X_tr.iloc[va_idx]\n",
    "#     y_tr_f, y_va_f = y_tr.iloc[tr_idx], y_tr.iloc[va_idx]\n",
    "\n",
    "#     mdl = xgb.XGBClassifier(**make_xgb_params(spw))\n",
    "#     mdl.fit(X_tr_f, y_tr_f)\n",
    "\n",
    "#     oof = mdl.predict_proba(X_va_f)[:, 1]\n",
    "#     fold_roc = roc_auc_score(y_va_f, oof)\n",
    "#     fold_pr  = average_precision_score(y_va_f, oof)\n",
    "#     fold_pr_scores.append(fold_pr)\n",
    "#     print(f\"[Fold {fold_id}] ROC-AUC={fold_roc:.4f} | PR-AUC={fold_pr:.4f}\")\n",
    "\n",
    "#     # --- æš«å­˜æ¯æŠ˜ test é æ¸¬ ---\n",
    "#     fold_pred = mdl.predict_proba(X_te)[:, 1]\n",
    "#     if fold_id == 1:\n",
    "#         all_fold_preds = [fold_pred]\n",
    "#     else:\n",
    "#         all_fold_preds.append(fold_pred)\n",
    "\n",
    "# # --- å°‡å„æŠ˜çš„ test é æ¸¬åŠ æ¬Šå¹³å‡ ---\n",
    "# fold_pr_scores = np.array(fold_pr_scores)\n",
    "# weights = fold_pr_scores / fold_pr_scores.sum()  # æ­£è¦åŒ–æˆæ¬Šé‡\n",
    "# test_proba_blend = np.average(np.vstack(all_fold_preds), axis=0, weights=weights)\n",
    "\n",
    "# print(\"\\nğŸ¯ å„æŠ˜ PR-AUC æ¬Šé‡ï¼š\", np.round(weights, 3))\n",
    "# print(\"âœ… å·²ä»¥ PR-AUC æœ€é«˜æŠ˜æ•¸çµ¦äºˆæ›´é«˜æ¬Šé‡å®ŒæˆåŠ æ¬Šå¹³å‡ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fae9a414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] ä½¿ç”¨å›ºå®šé–€æª» threshold=0.006\n",
      "Prediction label counts: Counter({1: 546, 0: 454})\n",
      "Saved: submission_first.csv âœ…\n"
     ]
    }
   ],
   "source": [
    "# ---- åƒæ•¸å€ ----\n",
    "THRESHOLD = 0.006          # å›ºå®šé–€æª»ï¼ˆæ²¿ç”¨ä½ çš„åŸå§‹å€¼ï¼‰\n",
    "MATCH_TARGET_COUNT = False    # æƒ³åŒ¹é…é™½æ€§æ•¸é‡æ™‚æ”¹ True\n",
    "TARGET_POS = 500              # é æœŸ test ä¸­çš„ 1 çš„æ•¸é‡\n",
    "# ----------------\n",
    "\n",
    "y_test_proba = test_proba_blend\n",
    "\n",
    "y_test_pred = (y_test_proba >= THRESHOLD).astype(int)\n",
    "print(f\"[Info] ä½¿ç”¨å›ºå®šé–€æª» threshold={THRESHOLD}\")\n",
    "\n",
    "# çµ±è¨ˆ\n",
    "from collections import Counter\n",
    "cnt = Counter(y_test_pred.tolist())\n",
    "print(\"Prediction label counts:\", cnt)\n",
    "\n",
    "# è‹¥ test æœ‰ ID æ¬„ä½å°±æ²¿ç”¨ï¼Œå¦å‰‡ 0..n-1\n",
    "if \"ID\" in test.columns:\n",
    "    id_series = test[\"ID\"].reset_index(drop=True)\n",
    "else:\n",
    "    id_series = pd.Series(np.arange(len(y_test_pred)), name=\"ID\")\n",
    "\n",
    "submission = pd.DataFrame({\"ID\": id_series, \"Label\": y_test_pred.astype(int)})\n",
    "submission.to_csv(\"submission_first.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved: submission_first.csv âœ…\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
